Topic,Count,Name,Representation,Aspect1,Representative_Docs
0,2,0_Mathematical Problem Solving,['Mathematical Problem Solving'],"['integrand', 'integrals', 'ey zero', 'zero', 'ey', 'solve', 'equals', '90 degrees', 'expression', 'ex']","[""So maybe one way of solving this problem is to search for u and v that makes that zero, or if you can't make it zero, make it as small as possible. And so that motivates this approach. Okay, so what's going on here? Well, the integrand is just this expression."", ""EY is not zero. And we know that there's a problem. If I move in this direction, the image doesn't change. So can't solve. OK, so EX equals zero is a problem. Similarly, EY equals zero is a problem. Just turned 90 degrees. So those are kind of obvious. I mean, we know those aren't going to work. Is there anything else? Well, how about EX equals EY? Well, if that's the case, then these two integrals are the same.""]"
1,1,1_Perspective Projection Motion,['Perspective Projection Motion'],"['motion brightness', 'brightness patterns', 'image motion', 'perspective projection', 'brightness', 'perspective', 'projection', 'patterns image', 'optical', '3d']","[""We'll start off by talking a little bit about review of things we've done last time, perspective projection, and a little bit about things that are relevant to the homework problem, particularly the last two questions. And we'll go from perspective projection to motion. So in perspective projection, we have a relationship between points in the environment and points in the image, and we found that we had this simple relationship between the 3D world and the 2D world, as long as we pick a suitable coordinate system with the origin at the center of projection and the z-axis along the optical axis, and so on. But then we're going to go from that to motion by differentiating that equation, and then we'll talk about motion of brightness patterns in the image itself. OK, so we had that, and then we had a vector version, which is only slightly more compact, so it's not, in this case, a great help. But we'll use both of them. We'll switch back and forth and use whatever is suitable for the problem that we're dealing with. So let's start with motion. So that's a static setup, and we can easily relate points in the environment to points in the image. Now, what if there's motion?""]"
2,1,2_Motion in Images,['Motion in Images'],"['image motion', 'motion image', 'differentiation', 'motion brightness', 'motion', 'differentiate', 'velocity', 'velocities', 'motion vector', 'motion focus']","[""What if that point in the environment moves? Obviously, there will be some motion in the image, and if we can find out what that relationship is, then maybe in some circumstances, we can invert that so that we can measure the motion of brightness patterns in the image, as you do in the homework problem, and somehow use that to figure out what's happening out in the world. So we just differentiate. We take our perspective equation, and we differentiate, so we get... Now, on the right-hand side, we have a ratio, and so there are two parts to the derivative, and we just apply the rule for differentiation of a ratio. And what I'm going to do a lot is reduce the intimidation level of the equation by substituting more easily digested symbols. So in this case, we've got all these derivatives. Well, what are they? They're really velocities, so there's going to be a velocity in the image in the x direction, which I'll call u, and there's a velocity in the real world in the x direction, which I'll call big U, and then we have a velocity in the real world in the z direction, which I'll call w. So that looks a little bit less scary, and of course, I can do the same in the y direction, so apply the same idea over here. So that's the forward direction. That is, if you tell me what the motion vector is in 3D, here's the formula to tell me what the motion vector is in 2D, and of course, we might want to invert that, but for the moment, let's go with that. Now, we can rewrite this in various forms, and since we'll use this a lot, let's do that. So one thing we can do is we can split up these terms into 1 over z, x over z, and why is that useful? Well, because we know that x over z is little x over f, so we can rewrite this using image coordinates, and we end up with f. And one thing this allows us to do is to ask the question, where in the image is there no motion? So if we're looking at the movement of brightness patterns in the image, there may be some places where there isn't any, and those are of particular interest. First of all, of course, we can find them using image processing techniques, and then because they tell us something about the environment or the motion. So you can see if we set this equal to zero, we find that's true at a point x naught, such that x naught over f is big U over big W, and similarly for this one equal to zero, and so the point x naught, y naught is that sought after point where there is no image motion, and we call it the focus of expansion. And in the case of a simple situation like I'm approaching the wall, the focus of expansion is the point towards which I'm heading. And so we can just express it directly in terms of the 3D motion vector, and you'll notice that this is actually just a projection of the 3D motion vector into the image plane. So I take that same diagram over there, and now instead of mapping the vector to the point p, I'm mapping the velocity. And if I do that, then that defines this point x naught, y naught in the image where there is no motion, and that's called the focus of expansion.""]"
3,1,3_Optical Flow Analysis,['Optical Flow Analysis'],"['recover motion', 'flow', 'unknowns', 'motion', 'constraint equation', 'frames', 'optical', 'vector field', 'solutions', 'constraint']","[""Over here, we have one constraint, that equation. We have one unknown, u, a perfect match. So we know that we are likely to get a finite number of solutions. And because it's linear, we get one solution. But when you look at this, you'll see there's one equation, one constraint. But we've got two unknowns, right? We've got u and v. So if we're trying to recover the optical flow, which is that vector field that we're discussing, it's like we don't have enough information here to do that, which is dramatically different from the 1D case where we had the match between the number of equations and the number of unknowns. OK, so what do we know? So are we lost at sea? Is it hopeless? So let's look at just what that constraint provides us. So again, the overall objective here is we have a time-varying image, or in the discrete case, a sequence of image frames. And we're trying to recover the motion. And we find that, assuming that things don't change in brightness, the images don't change as they move, we end up with that constraint equation. And what does it tell us? Well, one way to think about it is to plot it in velocity space. So we're used to plotting images with x and y as coordinate axes. But actually, for some purposes, it's useful to have a different kind of representation. And this is one. And what it means is that any point in here is a particular velocity, that velocity.""]"
4,1,4_Velocity Space Visualization,['Velocity Space Visualization'],"['velocity space', 'space', 'velocity', 'space used', 'velocity velocity', 'plot velocity', '2d world', 'constraint', 'focus', 'linear']","[""And for example, this is zero velocity. It's not going anywhere. Velocity space was used at one time in physics much more than it is now. And it's actually kind of neat. For example, if you look at planetary orbits, they're ellipses with the sun at one focus. And ellipses are sort of complicated. If you plot them in velocity space, they're circles, which was exploited in the early days before people could just feed equations into a computer and have them solved, where they had to reason about things geometrically. Anyway, velocity space is sort of neat. And here, we have a constraint in velocity space. So this is saying that, OK, before we opened our eyes and looked at the image, we didn't know anything. The velocity could be anywhere in this plane. But now we have one constraint on it. So what does that tell us that must somehow limit the solution space? And yes, it's a linear equation in u and v. And so a linear equation in a 2D world corresponds to what? Line, yes, y equals mx plus c, for example. So it's got to be a line. And that's great, because it means that, OK, we haven't solved the problem, but we've come a long way. So before, it could be anywhere. Now it's going to be on a line. And what we really like is to pin it down to a point. So we've come part way. And so what line is it? Well, we can rewrite that equation like that and rewrite it a bit more by normalizing this vector. So I'm turning this vector into a unit vector. So first of all, again, a reminder that this is the brightness gradient.""]"
5,1,5_Brightness Gradient Analysis,['Brightness Gradient Analysis'],"['brightness gradient', 'gradient important', 'brightness derivatives', 'gradient', 'brightness constant', 'brightness', 'unit vector', 'change brightness', 'vector', 'perpendicular']","[""And the brightness gradient is very important for all sorts of things. If it's 0, nothing much is happening, because the brightness is constant. And more likely, it has a high value at a transition. Now if I'm looking at transition between the wall and the blackboard, there's a big change in brightness and therefore the derivatives will be large and therefore the brightness gradient will be large. And not only that, but the brightness gradient as a vector will be pointing perpendicular to the transition, right, because EX is very large here, EY is zero. So this brightness gradient is very important. And this is a unit vector as you can easily tell by taking the sum of squares of the two components. And why am I doing this? Well, because I'm interested in the component of U and V in this direction, the direction specified by the unit vector, and it's this constant.""]"
6,1,6_Optical Flow Analysis,['Optical Flow Analysis'],"['direction brightness', 'coordinate', 'brightness gradient', 'perpendicular', 'gradient', 'constraints', 'distance', 'aperture', 'direction', 'constraint']","[""And so what this is saying is that, you know, U and V are perpendicular to some line. And this is what it looks like. You can check that. I mean, basically, you need to find this point and then calculate the distance from the origin and it's going to be that. So not too interested right now in the details of that other than that we've shown that it's a line and that the line depends on the brightness gradient. So it tells us a lot of things already. One of them is that when you make this localized measurement and you are under constraint, you don't have enough equations, you do know something. You know, for example, in this diagram, I don't know what U and V is. But suppose that I give you a different coordinate system. OK. Locally you're going to see linear patterns. You won't see that. If I keep on magnifying this, you know, it's going to be more and more like a linear relationship. And so the argument is that if you look through an aperture, you cannot determine the motion. You can determine the motion in the direction of the brightness gradient. So that's what we did over here. OK. So in the 1D case that we were done here, in the 2D case we're not done because we have a mismatch of constraints and unknowns. And so we need more constraints. We need to know something else. And sometimes, you know, there's prior knowledge of the environment that helps you. Sometimes you can look again at another time and get extra information. Now let's suppose that we have the optical mouse problem where the whole image is moving as one. You know, you're over a flat surface at a constant distance from the lens. And to a very high degree of approximation, the image is just moving as one. So we don't just have one pixel. We can do the same thing at two pixels. OK. That's at pixel one.""]"
7,1,7_Solving Linear Equations,['Solving Linear Equations'],"['pixels', 'constraints', 'matrix', 'pixel', 'constraint', 'linear', 'unknowns', 'linear equation', 'determinant matrix', 'noisy']","[""And that's at pixel two. And our job is to recover u and v. Well, it's two linear equations. We can write them that way. And then solve. Because we've got two constraints now, we have enough constraint to solve for the two unknowns. And, you know, it's just a linear equation, so it's very simple. We can actually write the answer out explicitly. So it's very mechanical. I mean, we just invert this two by two matrix and, you know, multiply the result by that vector and we're done. And what is this? Well, this is the determinant of that matrix. So you know, for two by two and three by three, we can explicitly write it down. Otherwise, we'll just use Gaussian elimination to solve the set of linear equations. OK. So in a way, we're done. We need two pixels. We can solve this. And now, you know, it's noisy. So we can improve the result by taking more than two pixels. But before we do that, it's always important to check the edge conditions like, you know, this can fail. And it fails when the determinant is zero, right? So when does that happen? Well, can that happen? Well, sure. Let's rewrite it one more time. OK. So we have this nice linear method that if we make these measurements at two pixels, we can solve for the motion. But it won't work if this is the case. So what is that? Well, this tells you something about the brightness gradient, right?""]"
8,1,8_Image Motion Analysis,['Image Motion Analysis'],"['brightness gradients', 'brightness gradient', 'direction brightness', 'brightness', 'gradient', 'motion brightness', 'gradients', 'parallel lines', 'constraint equation', 'tangent']","[""This is the direction of the brightness gradient. Well, the tangent of it, right? So what this is saying is that you have a problem if they're related. So this is where the they don't have to be the same. I mean, obviously, if the brightness gradients are the same, you subtract those two quantities, you get zero, and things blow up. But they don't have to be the same. They just need to be proportional to each other, right? We're just saying that the ratio of Ey to Ex is the same. And that makes sense, again, because that means that the brightness gradient is the same in the two places. That means that the constraint we get out of the equation is in the same direction. It's not providing new information. Or go back to this diagram. We now have two parallel lines. Well, if there's no measurement noise, they'll be on top of each other. And then you intersect them, and what do you get? Well, the same line. So that's not very interesting. Or if you have noise, it'll be even worse because they won't even intersect. So this tells you a number of things. One of them is, okay, this isn't gonna work if the brightness gradient is the same everywhere. And that makes perfect sense. That's the aperture problem. It also tells you that maybe you need to somehow weight contributions from different image regions based on this. Maybe you don't want to have contributions from a lot of image regions with the same brightness gradient because they're not really providing good constraint. They're all sort of doing the same thing. So that tells you that rather than take this result for two pixels and then apply it to other pairs of pixels and just take the average, you'll want to weight it in some way. Okay, and that's kind of kludgy. I mean, that's sort of trying to fix a problem in a simple way. But we can do this much better. So we have this equation that's supposedly true everywhere in the image. All right, this is our magic equation, which relates image motion to brightness gradients. And that's supposed to be zero. Now, if there's measurement noise, it won't be zero. Hopefully, it'll be small. If you plug in the wrong values of u and v, it won't be zero.""]"
9,1,9_Image Processing Errors,['Image Processing Errors'],"['integrand', 'image', 'zero hope', 'fail', 'hope lost', 'wrong values', 'lost', 'zero', 'values', 'perfect']","[""And if everything was perfect and you had the correct values of U and V, the integrand would be zero. And you integrate it over the whole image, you get zero. And that's the smallest you can get because it's quadratic, it can't get less than zero. So that's it. If you plug in the wrong values of U and V, well, it will not be zero. And so you can base a strategy for finding U and V on that. Now, there are cases where this is going to fail. One is if, I don't know, you're without a light in a coal mine, if E is zero, all hope is lost, obviously.""]"
10,1,10_Solving Linear Equations,['Solving Linear Equations'],"['constraint', 'texture', 'constant brightness', 'wall', 'ey zero', 'derivatives', 'brightness', 'linearly', 'linear', 'ey']","[""If E-X and E-Y are zero, all hope is lost. Because that means you're looking at a wall that's, you know, constant brightness and you won't be able to see it moving because there's nothing on it to catch your attention and to track. If there was some texture on it, then E-X and E-Y would not be zero in some places. OK. And so this is sort of an approach we're going to use a lot. So we have this constraint which would apply in an ideal case where we know the answer U and V. And we're going to take contributions of that. And now we can't just add them because some of them might be positive and some might be negative. So it doesn't make sense to minimize the integral of them. We turn them into something that's always positive by squaring it. And so we're going to find these answers by minimizing that. Now, in this case, you know, this is pretty straightforward. We now take that. And this is a calculus problem. So this is a function of U and V. And we're going to set the derivatives with respect to U and V equal to zero. And in this case, we're lucky enough that the equations are linear. And we can solve it. And actually, the answer is very similar to this. We're going to end up with two equations and two unknowns, right? One equation from the derivative with respect to U is zero. And one with a derivative of V is zero. OK. And so two equations, two unknowns, cool. But that can fail, right? Because they might not actually be different equations. They might be linearly dependent. So we'd want to worry about that. And in this case, the failure mode is. That turns out to be the determinant of that 2 by 2 matrix. So that corresponds to this thing over here. And in this case, that's when things fail. So when can that happen? Well, certainly if E is zero or E is a constant, right? Because then EX and EY are zero.""]"
11,1,11_Isophotes and Gradients,['Isophotes and Gradients'],"['isophotes', 'ey zero', 'integral', 'ey', 'ex', 'draw', 'brightness', 'zero', 'constant', 'direction']","[""Or maybe if just EX is zero everywhere, right? Because then this integral is zero. And that integral is zero. So let's see. So if EX is zero and EY is not zero, what is that? Well, that means that I have one of those pictures that only varies in one direction. EX is zero, meaning it's constant in the horizontal direction. EY is non-zero. It's varying in brightness in the vertical direction. And if I were to draw isophotes, they'd look like this, right? So here, EX is zero.""]"
12,1,12_Image Coordinate Rotation,['Image Coordinate Rotation'],"['brightness gradient', 'brightness', 'rotation', 'coordinate', 'angle', 'isophotes', 'gradient', 'isophote', 'axis', '45 degrees']","[""And actually, that integral is the same also. So we're going to get integral EX squared, all squared, minus this thing all squared, zero. So that's bad. So what is that? Well, that's where isophotes are running at 45 degrees, right? Because the brightness gradient has the same x component as y component. The brightness gradient is perpendicular to the isophote. And so EXEY means it's a 45 degree angle for the gradient. So the isophotes are 45 degrees down. So that's the picture for that. And of course, that is really the same thing as that, just rotated. And one of the things we're going to do is say that, well, something shouldn't depend on our choice of x and y in the image coordinate system. I mean, the answer would be different. But in the new coordinate system, it should mean the same thing. So in this case, I shouldn't get some result that's particular to the x or y-axis. It should just give me the same result if I rotate. So that's a 45 degree rotation.""]"
13,1,13_Mathematical Transformations,['Mathematical Transformations'],"['rotation', 'integral', 'ey ex', 'ey', 'angle', 'tangent', 'ex', 'squared', 'constant', 'll']","[""I can get any rotation by doing something like that, right? Because then EY over EX is some constant. And that's the tangent of the angle of rotation or something like that. Plug that in here. And of course, you'll see that you get k squared times the integral over here.""]"
14,1,14_Isophote Analysis Concepts,['Isophote Analysis Concepts'],"['isophotes', 'isophote', 'curvature', 'brightness gradients', 'squared', 'angle', 'parallel lines', 'parallel', 'tangent', 'gradients']","[""And the k squared appears over there. They cancel each other out. So this is actually the most general case. All of these others are just special cases of that one. So that summarizes all of the cases we found. They're all with isophotes at some angle, parallel lines. And then the important question is, is that it? And it turns out, yes, that's it. And it's not easy to prove. You need to at least use the triangle inequality or something profound like that. So it's actually not that hard. But I think it's not really useful to go there. Anyway, so when can we do it? Well, as soon as there's curvature in the isophotes. Because if the isophote looks like this, if I move it sort of tangent to the isophote, there are still changes. So the only problem is where the isophotes are all parallel straight lines. And in another way of thinking about it, if you have areas in the image where there's a, quote, corner, something where the isophote makes a sharp turn. So here are the brightness gradients.""]"
15,1,15_Image Gradient Analysis,['Image Gradient Analysis'],"['brightness gradients', 'brightness', 'gradients', 'areas image', 'areas', 'curvature', 'places', 'area', 'purposes', 'image']","[""If there's some small area where the directions of the brightness gradients change a lot, that's good. Because what we're worried about is that the brightness gradients are all parallel to each other. That's the bad situation. And so for many purposes, like image alignment and recognition, we look for places that are, quote, interesting. And one interesting way is to look at the isophote curvature or equivalently the rapid turning of the brightness gradients. Because in other areas of the image, there's less constraint.""]"
16,1,16_Image Noise Analysis,['Image Noise Analysis'],"['gradient', 'pixels', 'brightness gradient', 'image looks', 'noisy', 'noise', 'image', 'constraint', 'brightness', 'bits']","[""If I have a part of the image that looks like this, on its own, it doesn't provide enough constraint. Now, if next to it is another area of the image where things look like this, if I have both of these, then that's fine. But if everything has the same gradient direction, that's not satisfactory. OK. OK, so homework problem, theoretically due on Thursday. And I know we haven't done a whole lot on this. So if you have problems with it, send me an email. And I may say something that doesn't give away the answer but helps you. And we'll go from there. What we're going to do next is talk a little bit about this concept of noise gain. So the idea is that all this time in the back, we've been thinking about, oh, we only have pixels with eight bits. And they're noisy. And our calculations are going to be flaky unless this determinant is large. large, and so on. So there's a lot of attention to not just a formula for computing the answer, but making sure that the answer is actually meaningful, as opposed to you've taken two noisy numbers and divided them by each other, and the result is not very predictable. So in noise gain, that's a very precise way of talking about it, which is saying, if I make this much of a change in the image, what is the change in the result? So in this case, I'm trying to get the velocity of motion. How much is the velocity of motion going to change if I change the brightness gradient somewhere? I have the wrong measurement. It's slightly off. And of course, we want that to be not sensitive.""]"
17,1,17_Image Motion Analysis,['Image Motion Analysis'],"['brightness gradient', 'image motion', 'gradient', 'motion image', 'constant brightness', 'curves', 'curve', 'derivatives', 'brightness assumption', 'derivative']","[""We're just taking the derivatives in those three directions, whereas we could be doing something more complicated, so let's think about that. So suppose that, you know, this video is from me moving through an environment, and there's some object in the environment that I'm tracking, and at time t zero, you know, it's there in the image, and then in the next frame, it's over here, and so on. So it follows some sort of path in this three-dimensional volume, and, you know, I could do this for other points and develop this whole set of curves, but let's just focus on one. Now, one of the things I might want to do is see how this changes. So when I'm looking at different frames of an image, often what I want to do is not take the derivative at a pixel and see how it changes to the next time frame, but I want to follow an object and see how it changes, and in many cases, I'm going to make the constant brightness assumption that it's not changing in brightness, and so I would like to express some constraint on the derivative along this curve, and so I could have a curve. How do I define that? Well, one way is to give x and y as a function of t. So this green curve, for each time t, I can give an x and a y. That's how I define that curve. And then what I'd like to do is look at, for example, the total derivative along that curve, keeping in mind that along that curve, not only is t changing, but x and y are changing in some defined way. So this is the total derivative, and in what we're going to be doing, we'll set that to zero because we're assuming that this point maintains its brightness. And then I can use the chain rule to split this up. So I'm going to get dx dt times dE dx plus. So I can take this total derivative and express it in terms of partial derivatives. And again, that looks kind of intimidating, but I can easily rewrite this. So that's equivalent to what we had for 1D motion. So this is showing a relationship between the brightness gradient and the image motion. And if I know the image motion and I know the image, I can predict how it's going to change. It's very simple. I just use this formula. And what we're more interested in doing is we've got images, image sequences, and we want to find u and v. So that's where we're going. Now, over here, we could just solve for u because we have a single equation in a single unknown. And that's another thing we're going to do a lot is equation counting. How many degrees of freedom? How many numbers are there that we don't know? And how many constraints do we have?""]"
18,1,18_Understanding Partial Derivatives,['Understanding Partial Derivatives'],"['brightness', 'pixels direction', 'pixels', '2d', 'frames', 'volume', 'partial derivatives', 'axis', 'derivatives', 'image']","[""So let's extend this analysis to 2D and see what happens. Now, some of this may seem tedious and repetitive to some of you, but we're all on different wavelengths. So I'm going to get the next result in several different ways. And different approaches may appeal to different people. So let me do it this way. So let's start by talking about the image volume. So, think about, you know, video, and we're stitching together the frames, so each of these cross sections is a frame, and we end up with this three-dimensional thing, which is, you know, brightness as a function of x, y, and t. And typically, in practice, we slice it across this way, but we could slice this volume any way you like, and in some cases, there are advantages to slicing it in different ways. Okay, so that's part one, and sometimes it's useful to visualize things this way. Then we're going to be using partial derivatives, so what are they? Well, it's just the derivatives in the axis direction here, so we'll be dealing with, you know, dE dx, dE dy, and dE dt. And just as we've been discussing, we approximate them by taking differences, first differences of neighboring pixels in either the x, the y, or the t direction from frame to frame, so you know, that's all that is. Okay, so what's, you know, some people find partial derivatives a little bit more scary than ordinary derivatives, but that's all it is.""]"
19,1,19_Statistical Image Processing,['Statistical Image Processing'],"['pixels calculation', 'pixels', 'use pixels', 'pixel', 'statistics', 'average', 'images', 'measurements', 'calculation', 'improve']","[""Then we use those two pixels to do the calculation. And so we add them up. So we have a lot of noisy measurements. And we take the average. And magically, things improve. And so just without going into hairy statistics or assumptions about probability distributions, roughly speaking, when you average n values, you reduce the standard deviation by the square root of n. And when you have these political surveys and they say they have a 5% margin of error, what they mean is that they talk to 400 people, right? Because square root of 400 is 20. 1 over 20 is 0.05. So same principle. So it doesn't improve linearly with n, unfortunately. That would be even better. But it does improve with the square root of n. So if we have a million pixel image, it improves by a factor of 1,000, which is pretty significant. OK, now if we just did this in this simple way, we'd still run into trouble. First of all, if e x is really 0, you'd be dividing by 0. So you can't do that. I guess you could leave those pixels out. And then if e x is small, you still have an answer which is relatively bad. So there are places where the slope is large, where you get good information. And now you're polluting it by adding in as an equal information from places where the slope is low. And that's why in the homework problem, we talk about weighting. So don't just take an average and treat each of them equally, but multiply by some weight factor. And then, of course, what happens to the 1 over n? Well, you have to compensate for the fact that you've now switched to using weights. OK, as we mentioned, images are really 2D.""]"
20,1,20_Vector Mathematics Concepts,['Vector Mathematics Concepts'],"['cross product', 'product cross', 'vector', 'cross', 'vectors', 'flow', 'image motion', 'equations', 'motion', 'perpendicular']","[""I mean, if we just write out the components of that equation, we get what we had before. Then I just want to do one more little trick, which is in the appendix of the book, we have some useful information about the time So in the appendix of the book, we have some useful results about all sorts of simple math that's needed, one of which has to do with vector equations and with manipulating cross products of cross products, that kind of thing, which I typically don't remember how to do. So I'll go to the appendix of the book. And the appendix is under materials on the Stellar website. OK, so let me first transform this one more time. So we've got OK, that's just rewriting this. And now we use a result. And the reason we do this is because it allows us to make some general statements about the flow. OK, so cross product of cross products can be expressed as the difference of dot products. Now you can match up these two lines. And you can see where we're going with this, which is OK, so finally there we have the image motion expressed in terms of a world motion. using this somewhat odd-looking expression. So why is this of interest? Well, the first thing you can say is that the result is perpendicular to z. Because if you take the cross product of two vectors, the result is perpendicular to both of the vectors. So r dot equals 0, r dot z equals 0. So is that surprising, that the image motion is perpendicular to the z-axis?""]"
21,1,21_Motion and Expansion,['Motion and Expansion'],"['focus expansion', 'image plane', 'image motion', 'expansion moving', 'focus', 'inverting', 'motions', 'expansion', 'motion', 'image']","[""Okay, that's a useful thing, because if you can find the focus of expansion, all you need to do is connect that point x naught, y naught to the origin, and you have a vector that tells you the direction of motion. So a nice example of inverting that process. Okay, now once we have the focus of expansion, we can rewrite those equations yet one more time. And so there are a couple of things there that are of interest. One of them is that the f's cancel, so we can do that. And then we actually can get an idea of what the image is going to look like. So let's suppose this is the image plane. Now we're looking at it straight on. And suppose that this is our focus of expansion. And we're moving with respect to, the environment is moving with respect to us, so we're moving with respect to the environment. Einstein said that it's all relative, it doesn't matter. The only thing we can determine is the difference in the two motions. Then there will be no image motion here, and what about other places? Well, this tells you exactly what the pattern will be like, right? So if we go to the right, such that x naught minus x is positive, while we keep this one zero, what happens is, well, u will become larger. The further we go away, the larger.""]"
22,1,22_Vector Motion Diagrams,['Vector Motion Diagrams'],"['image motion', 'vector diagram', 'motion point', 'vectors point', 'vector', 'vectors', 'motion', 'vector tells', 'little vector', 'direction']","[""So if we go to the left, the larger. So we'll have a little vector here that tells us the image motion at that point, and another vector over here, which is perhaps larger. And then we can go to where this is negative. So the other side, draw a vector here. Okay. So I'm starting to draw a little vector diagram of the motion field, if you like, how things are expanding from that point. And I can do the same in the y direction. So suppose I keep x naught equals x, but I change y naught. So I'm going along this line. I'm going to get vectors that point this way.""]"
23,1,23_Vector Diagrams Explanation,['Vector Diagrams Explanation'],"['focus expansion', 'perspective projection', 'expansion moving', 'projection', 'focus', 'expansion', 'perspective', 'vectors point', 'angle', 'distances']","[""I'm going to get vectors that point this way. And let me be adventurous and go off at right angles where x naught minus x is the same as y naught minus y. Well, that means that u and v are going to be the same. That means I'm going to get a vector at 45 degrees, right? And opposite direction like that. And I think you can see that we're going to fill in this whole diagram, this little vector diagram with arrows that are pointing outwards from the focus of expansion. That's what this equation says, that all these vectors are radiating outward. And that's why it's called the focus of expansion. So I'm moving towards that wall, and this is the place I'm actually going to hit. I may be going at an angle, but my whole image is looming. It's zooming outwards, which is a useful clue, a useful cue for measuring distance and velocity. Well, as you saw in the homework problem, there's this scale factor ambiguity that because of perspective projection, we can't actually tell absolute distances. And we have a similar phenomena here. But what we can tell is this ratio.""]"
24,1,24_Vector Transformation Concepts,['Vector Transformation Concepts'],"['focus expansion', 'surface', 'focus', 'field', 'term', 'inverse', 'ratio', 'image', 'moving', 'expansion']","[""So this whole field depends critically on that ratio. So what is that? W over z. And if I make that larger, then the vectors will be larger. That means I'm sort of getting closer to the surface I'm about to hit it. Conversely, if I make it smaller, that will be smaller. If I make it negative, what happens? Well, all of these vectors are reversed. So it's a focus of compression. There's no such term, but we could call it that. It's just the inverse of the focus of expansion. And that's what happens if I'm moving away from the surface. I'm taking off from the lunar surface, and the image is sort of compressing as I leave. OK, well, so what is this? Well, let's turn it on its head. What is z over w?""]"
25,1,25_Calculus in Physics,['Calculus in Physics'],"['rate change', 'rate', 'dt', 'surface', 'useful information', 'quantity', 'ratio', 'derivative', 'useful', 'imaging']","[""And w, of course, is the rate of change of z. So we've got z over dz dt. What are the units of that? So z is in, say, meters. And dz dt is in meters per second. So the units of that ratio are seconds. And so can you think of what that quantity is? Sorry? Time to impact. Great. So that's going to tell me how long it's going to take before I crash into the surface. And so that's a quantity that we're going to spend some time thinking about, both because it's important if you're, say, landing NASA craft on Europa, or if you're a fly landing on the ceiling. And also, it turns out to be relatively easy to compute compared to some of the other things that we'll be looking at. By the way, the landing on Europa is a JPL RFP. They wanted to have industry give them ideas of how they're going to do that and how much it's going to cost. And well, we told them that this is the right way to do it, and we never heard from them again. So I don't know. So if that craft crashes on Europa, don't blame me. I told them what to do. OK, so this is beginning to look kind of promising, because we can actually see a way to inverting this imaging process and getting some useful information just from the way the brightness pattern in the image changes. But I need to torture you a little bit more and do this in vector form. And we'll see later why this is useful. Right now, it's not saving us a whole lot in terms of writing, going from the component form to the vector form. But we'll see that it does eventually. OK, so instead of differentiating the component versions, we're going to now differentiate the vector form. And of course, it's very similar. So what's the time derivative of a vector?""]"
26,1,26_3D Motion Analysis,['3D Motion Analysis'],"['means vector', 'dot', 'vector', 'motion', 'differentiation', 'ratio', 'notation', 'distances', 'ok dot', 'expansion']","[""Well, it's just the vector where you've differentiated each of the components with respect to time. So it's nothing very fancy. So we have that term again that corresponds to this first part here. But because it's a ratio, and because R can be changing, big R can be changing, we need to take account of the fact that it's a ratio. And we get. And OK, so to make it look slightly less intimidating, we'll switch from Leibniz to a Newtonian notation. Again, the underline always means that it's a vector. And I'm splitting this up a bit. OK, so the dot here denotes differentiation with respect to time. And so we have two terms, one of which is sort of obvious scaling, that there's a certain motion in 3D, and it's going to be magnified or demagnified by the ratio of these two distances. So there's a big motion out here. It's a smaller motion in there by the ratio of those. But then there's this other term that corresponds to motion in depth that we have to take into account. And I rewrote it this way because, again, we can make use of the fact that we have this perspective projection equation. And so we can introduce the image coordinates. So focus of expansion, again, would be where r dot is 0. And so that corresponds to z. Let me put the 1 over f on the other side. That's easier. And so we basically get the same equation.""]"
27,1,27_Image Motion Analysis,['Image Motion Analysis'],"['image motion', 'image 2d', 'motions', 'motion', 'axis', 'velocity', 'problem image', '2d', 'velocities', 'image']","[""So image motions in that plane, z-axis is there. Now, of course, it's obvious. I mean, it couldn't be any other way. If we got it, this is a good way to check the result. If we got anything else, there'd be a problem. So in the image, we only have 2D. We have x, y. And we have, as velocities, u and v. We don't have a velocity in the z direction that would be popping out of the image. So that's interesting. And then something else we can look at is what if the image motion is radially outward or inward?""]"
28,1,28_Discrete Calculations Overview,['Discrete Calculations Overview'],"['pixels calculation', 'pixels', 'use pixels', 'discrete world', 'approximate', 'continuous world', 'calculation', 'discrete', 'forth continuous', 'continuous']","[""And the reason we can do it is because we got lots of them. So we talked about how to approximate, how to switch back and forth between the continuous world and the approximate discrete world. And now, I don't want to give away the solution to the homework problem. But the next step, I guess, would be to get a bunch of these and combine them. So we might do something like this. If we have n pixels, then we might try something like this. So now, instead of just using two pixels, we use those two pixels to do the calculation. Then we use these two pixels to do the calculation.""]"
29,1,29_Image Motion Analysis,['Image Motion Analysis'],"['image motion', 'motion focus', 'motion point', 'motion', 'motion vector', 'moving wall', 'angle', 'point image', 'focus expansion', 'vector point']","[""That is, the motion is along the radius vector to the point in the scene. What do you expect will happen to the image motion in that case? So you have the baseball coming straight for you. Its image is doing what? It's expanding, but it's not moving, right? So this is the case where we would expect the image motion to be 0. And now we check this formula. OK, if r dot and r are parallel, and we take their cross product, the cross product's length is proportional to the sine of the angle between the two vectors. Well, if they're the same vector, then that angle is 0. And so the sine is 0. And so this formula, while it took a little bit of work to get there, it's helpful for answering certain questions. And we can right away check things like this. OK, if the thing is coming straight at you or you're moving directly towards it, there will be no image motion. Well, that's our focus of expansion, right? So if I'm moving towards the wall, that is the point where the motion vector lines up with the direction to that point. And so I get no image motion. OK, while we're here, we can look at some flow fields. So we already saw a flow field up there for a general motion towards some point. And we could look at just a couple of other cases. So let's suppose that u, v, and w could be anything. But let's make it OK. So we're assuming now that two of those components are 0. So there's only motion in the world in the x direction. And then what do we expect in the image? Well, from our formulas, we see that the only component of the image motion is little u. So if the world is moving in x or I'm moving in x relative to the world, then the vector field of how brightness patterns move in the image looks like this. One thing to note, though, is that the length of those vectors is not the same. That the length depends on z, or if you like, the inverse of z, and so on. So if you look at all of these formulas, we've got r dot z, which is big Z. And look at those formulas up there. You've got 1 over z. So yes, this is a very simple vector field. But the vectors aren't all the same. So that kind of is unpleasant. At the same time, when something's unpleasant, you can sometimes take advantage of that. So in this case, if we had a vector field like this, one thing we could try and do is recover depth. Because these things are all inversely proportional to depth. Again, an illustration of how, once we understand the forward process, we can trim that around to try and solve the inverse problem. OK, u is 0. And let's try this one. Well, that's just turning everything 90 degrees. So that's not very interesting. The same idea. Now, I guess to exploit this idea of recovering depth from these fields, we would need to know z. We need to know the velocity. So there's sort of two things affecting what these pictures look like. One is the object, the shape, the distance. And the other one is the motion. And if we know either one of the two, then we can calculate the other one. Of course, in practice, often we don't know either one. And we'd like to recover both. And then often, we end up with an ill-posed problem. How about u is 0, b is 0, w is not equal to 0? Well, we already drew that diagram up there, kind of. If we look at the equations, we're just going to get FOE is. So that's the simplest case of that picture, where the focus of expansion is right in the center of the image. Well, this is starting to hint at some of the things we're going to pursue. We develop the equations for some transformation like this between something in the world and something in the image. And then we try to invert it. And the forward one is always simple. There's the equation up there. You just plug in whatever. The inverse isn't, because often there may be more than one solution. Or there may be no solution.""]"
30,1,30_Image Processing Concepts,['Image Processing Concepts'],"['brightness patterns', 'brightness', 'brightness power', 'motion image', 'color', 'image 2d', 'images', 'gray', 'image', 'unit area']","[""Or there may be an infinite number of solutions. Or it's ill-posed in the sense that if you make some small measurement error, the answer is going to be perturbed by a large amount. So we'll have to be careful about that. But talking of motion of image brightness patterns, let's talk about that. That's in the homework problem. So let's talk a little bit about that. So we'll ignore for the moment where these images come from. What is an image? Well, an image is a 2D pattern of brightness values. So it's e as a function of x and y, if you like. And we already said something about that in terms of brightness being power per unit area. We'll make that more clear later on. So his question was, what about color? And yes, we will be talking about color at some point, which is kind of, in a way, this is repeated three times. And a couple of reasons not to bring it in at this point. One is we'll do it more simply just using gray levels. And then color is peculiarly human-centric in that the only reason that we use three numbers to represent color is because our particular color sensing system has three sensors. But we'll talk about all of that later on. For now, assume that we have taken RGB and turned it into brightness, which is, depending on who you read, some combination of the three components, mostly g, because human vision is most sensitive to g and judges absolute brightness based on some combination of R, G, and B. Now, a couple of things I'm going to do repeatedly. So I want to kind of preemptively talk about them. One of them is I'm going to be switching back and forth between continuous and discrete. So these days, with everything being digital, of course, the images we get are discrete. They're quantized.""]"
31,1,31_Image Analysis Techniques,['Image Analysis Techniques'],"['constant brightness', 'brightness pattern', 'brightness', 'brightness assumption', 'brightness constant', 'quantized', 'brightness power', 'pixels', 'change brightness', 'brightness doesn']","[""They're quantized in space and typically on a rectangular grid. which is kind of not the best grid to use, but that's what we use, and then in brightness. So, we also don't get continuous values for brightness. We get them quantized often to as few as eight bits. But it turns out that a lot of what we do is easier to understand in the continuous domain. So, I've talked here about E of X, Y, that's my brightness pattern for any X and Y. It'll tell me what the brightness is, the power per unit area. But in practice, it's going to be more like I have an array of numbers with two indices and I'm dealing with E sub whatever. Correspondingly, in the continuous domain, we'll often be taking integrals. For example, with some measurement that's local at a pixel, but we want to extend it over the whole image, and we take either a single integral or a double integral. Well, of course, in the discrete world, we'll be taking sums. But those are very straightforward transformations. But they're very useful because on the one hand, we want to implement this as actual code, and on the other hand, we'd like to make it easier to develop the map, and it's almost inevitable that it's easier in the continuous world. Then we get the derivatives. So of course, in the continuous world, I can look at the X and Y derivative of brightness, and the combination of these two is called the brightness gradient, which is going to be very important in many of the things we do. In practice, I'm going to approximate those by making some difference. First difference, and we'll see that that's one way of doing it. It's not a particularly good way of approximating the first derivative, but we'll talk about others. I don't know, just in terms of writing, this is easier to write than that. So I know that's not a big argument, but we'll find that some of these things have a closed form solution in the continuous domain that you can easily obtain, and it's harder to do the same in the discrete domain. So I'll be switching back and forth. Okay. With that in mind, let's look at our 1D image. So of course, images are typically 2D. There are 1D sensors, and they have some benefits. One of them is that you can build a 1D sensor with a much larger number of pixels in one direction than you can a 2D sensor. So a 2D sensor, although these days, 2D sensor could be, I don't know, 2K by 4K, some huge number. But linear sensors have been around with many thousands of pixels, and the disadvantage of a linear sensor is to get a real image, you need to scan it. This is done quite a lot in industry, where things are moving along on a conveyor belt, and you can use a relatively cheap, very high-resolution linear array sensor, and the conveyor belt motion provides the other dimension of the image. It's also used in satellite imaging, where very high-quality 1D sensors are used, and then the motion of the satellite provides the scanning to produce an image. Anyway, suppose we have a 1D image, and suppose things move. So this is at time t, and this is at time t plus delta t. Think of your optical mouse, you're holding it down on the table. It has a short focal length lens that's imaging the surface of the table, and if there's some texture to it as there is on the wood over here, then that texture is mapped onto the image, and if you move the mouse, then the image of that surface will move, and your job is to accurately estimate how fast it's moving. So here's the picture before, two time steps, and so we're trying to figure out how do I determine what happens. So let's suppose we have a velocity of u, and so we've moved by that amount. So let me indicate that over here. So that's delta x. Now, we're making some assumptions here that we'll get back to in a second. One of them is that the brightness doesn't change, and so if your optical mouse is looking at the surface of the table, then presumably between one frame and the next, the illumination isn't changing. It's using an LED with a constant current, and it's taking 2,000 frames a second. So it's unlikely to change. The geometry is changing a little bit because you've moved, and now you're looking at the surface from a slightly different angle. But for most surfaces, the change in brightness due to that is very small. So right here, the way I've drawn these curves, I've assumed a constant brightness. So let's get it right out front, constant brightness assumption. We'll see that there are circumstances where that doesn't apply, but there are lots of cases where that is the case. For example, as I'm walking around the room, your shirt still looks maroonish red, and it doesn't really change. And so we are used to most of the world being somewhat constant in color, constant in brightness as well, even though we know that there are circumstances where that's not the case. For example, if I look at the reflection of the lights up there in my cell phone, they of course move relative to the cell phone as I move around. And we'll talk some more about that. OK. So let's sort of enlarge a little piece of that. OK, so we're blowing up this area. And why am I doing that? Well, I'd like to use a linear approximation. So I'm assuming that this curve, so second assumption, I'm assuming for the moment this curve is relatively smooth, such that if I look at a small enough part of it, I can approximate it as a line. OK, and then there's a change in brightness. And there's some slope here. And the slope relates the motion to the change in brightness. You can see where this is going. I'd like to use the change in brightness to determine the motion. Because how else are we going to measure the motion in the image? The pixels stay in the same place.""]"
32,1,32_Image Motion Analysis,['Image Motion Analysis'],"['brightness gradient', 'gradient', 'differentiation', 'slope', 'derivatives', 'derivative', 'brightness', 'partial derivatives', 'rate change', 'single pixel']","[""All we've got is the brightness of the pixel is changing. And somehow we have to invert that relationship. OK, so in terms of E of x and t, what is this slope? All right, so this is in the x direction. And that's the rate of change of E with x. And so it's dE dx, OK, slope. And I'm going to write it that way as a partial derivative. And I'm going to write it as a partial derivative. Might as well use the correct notation right away. We're going to need partial derivatives because we have both x and y and t. And so we need to be clear about which type of differentiation we're talking about. OK, so then that's the slope. So that means that delta E must be the slope times delta x. And so that's going to be, and I'm going to write this as E sub x. So again, in order to simplify notation, I will often use subscripts to denote partial derivatives. And E sub x and E sub y, we use so much that it would be a pain to have to write them out in full every time. As we indicated, those are the components of the brightness gradient, which is used for all sorts of things, including edge detection. OK, so now let me divide through by delta t. And this, I guess, in the limit as I take smaller and smaller time steps, is going. to be that partial derivatives. And if you like, I can revise it one more time. OK, so you can see here why using the switch to the continuous domain is helpful, because I can take the limit here as delta t approaches 0 and get the partial derivative. Of course, in practice, I'm getting frames at a fixed rate and they have a certain interval. I can't make that interval infinitely small. So I end up with a much messier expression. But the two are obviously related. OK, so that's the result for a 1D image. And that allows us to recover the motion. So one thing I probably glossed over is that as we go from t to t plus delta t, the brightness decreases. So this delta e over here is actually, for a positive slope, the delta e will be negative. So that may have gotten lost in here somewhere. OK, so remarkably, from a single pixel, I can get the velocity in this 1D case. Now, importantly, that's not true in the 2D case. And after all, that's the case we want to solve. So we're going to have to work a little bit harder. And now, a couple of things you'll see. First of all, the faster things are moving, the larger e t will be. Well, that's no surprise. If the brightness is changing slowly, then you speed things up, then the brightness will change more rapidly. It's like taking your YouTube video and changing the playback rate.""]"
33,1,33_Playback Rate Changes,['Playback Rate Changes'],"['playback rate', 'brightness', 'rate change', 'playback', 'rate', 'velocities', 'changes', 'change', 'rapid', 'll notice']","[""When you change the playback rate, you change all the velocities by the same factor. And then you have more rapid changes of brightness. Intuitively obvious. Another thing you'll notice is that there's a problem if e x is 0.""]"
34,1,34_Pixel Brightness Measurement,['Pixel Brightness Measurement'],"['brightness derivatives', 'brightness', 'brightness gradient', 'single pixel', 'approximating', 'pixels', 'brightness doesn', 'approximating derivative', 'pixel', 'measurement']","[""We can't do this if e x is 0. So if we're, for example, at suppose we are up here, well, then if the thing moves, the brightness doesn't change or changes only a tiny bit. And so from that, you can't really tell how far it moves. You pretty much have the same result if it moved that much or whatever. And just in terms of implementation, you're dividing by 0. So that's not going to be good. And it's not just 0, it's when it's very small. Why is that? Well, because when it's very small, it probably means that you don't know it accurately as a result of the fact that you obtain it by subtracting two pixel values. So let's just, again, go over this. We're approximating this by saying it's 1 over delta x e of x plus delta x. Well, that's fancy notation, but basically they're two pixels. We take this value, and we subtract that value. So we read out the gray level there, read out the gray value there, subtract them. And that's how we estimate our brightness derivatives. And similarly, so what do we do with ET? Well, ET is derived the same way, except that we have two frames. And we pick the same pixel out of the two frames, and we subtract their gray values. So it's just in a different direction that we're approximating the derivative. And why is that important? Well, if there is a small brightness gradient, e of x is small, then those two values will be very similar. And since they are not known precisely, they have measurement error in them, we're now subtracting two quantities that are similar in size. So we get a smaller quantity. It's mostly noise at some point. So that tells us that this is something to avoid. We don't want to be, and it makes sense. I mean, if the image is uniform in brightness, e of x is 0, you can move it, and you can't tell that it moved. I mean, you'd have to have some reference point, like some texture on it, to tell that it moved. And if you had texture on it, e of x wouldn't be 0. So I know I'm sort of belaboring this over and over again. But it's very important, because it means that this type of measurement is, A, very noisy, and B, not trustworthy, unless certain image conditions are satisfied. And then the next thing you can do and say, well, wow, we can estimate velocity from a single pixel. But we've got lots of pixels. And that's part of what we're going to be using heavily, that, OK, the single pixel result is not great, but we got a million or 10 million. And so we can do things like least squares to improve the result dramatically. So it may be that the result from a single pixel is really flaky, but that's OK, because we divide the error by 1,000 if we think about the statistics of having a million of these pixels. So I keep on saying they're noisy. And at the same time, I'm saying we can do this.""]"
35,1,35_Inverse Function Stability,['Inverse Function Stability'],"['invert', 'noise', 'transformation', 'forward', 'noise ll', 'function', 'sensitive', 'questions', 'don', 'll']","[""We don't want it to be very sensitive to noise. And so we'll make that clear in terms of a one-dimensional transformation, where we know the forward function, and we're trying to invert it, and we want to know when that inversion is sensible and when it's not. OK. Oh, questions?""]"
